---
title: "Uma breve análise sobre o PIB per capita dos Estados Brasileiros no ano de 2019"
author: "Alisson Rosa e Vítor Pereira"
header-includes:
   - \usepackage[brazil]{babel}
geometry: margin=2cm
output:
  bookdown::pdf_document2:
editor_options:
  chunk_output_type: console
---

```{r setup,include=F}
library('tidyverse')
library("tidymodels")
library('kableExtra')
options(digits=3)
options(scipen=999)
options(OutDec=",")
theme_set(theme_bw())
knitr::opts_chunk$set(echo=FALSE,message=F,warning=F,fig.pos = 'H',fig.align = 'center',fig.width=7.8, fig.height=4)
scale_fill_discrete = \(...) scale_fill_brewer(... , palette="Set2")
df=read_csv("https://raw.githubusercontent.com/AlissonRP/gdp-statesBR/main/df")
df=df %>% 
  select(UF,PIB=GDP,IDHe=`HDI Education 2017`,Área=Area,`Densidade Demográfica`=`Demographic Density`,Pobreza=Poverty,Região=Region) %>% 
    mutate(Região=fct_recode(Região,"Norte"="North",
                             "Nordeste"="Northeast",
                             "Centro-oeste"="Center-west",
                              "Sudeste"="Southeast",
                              "Sul"="South")) 
df1 = df  
df = df[-7,]
```


```{r, funções}
#Dispersão/ correlação
d=function(df,v1,v2,px){
  df %>% 
    ggplot(aes({{v1}},{{v2}})) +
    geom_point(size=2.1,color="red")+
    annotate(x=px, y=55000, 
         label=paste("Correlação=", round(cor(df %>% 
                                         select({{v1}}),df %>% 
                                         select({{v2}})),2)), 
         geom="text", size=5)+
    ggrepel::geom_text_repel(aes(label=UF),size=2.8,point.padding = 0.3)
}
tbl=function(v,tit){
  v %>% 
    kable(caption=tit,align = "c") |> 
  kable_classic(latex_options = "HOLD_position") 
}
graph=function(df,l){
  df %>% 
    as_tibble() %>% 
      ggplot(aes(as.numeric(row.names(df  %>% as_tibble())),value))+
      geom_point(color="red")+
      geom_hline(yintercept=l, linetype="dashed", color = "navy")+
      geom_hline(yintercept=-l, linetype="dashed", color = "navy")+
      labs(x="Índice")
    
}
```

\section{Introdução}
A proposta do respectivo trabalho é predizer o produto interno bruto per capita (PIB) de 26 estados do Brasil no ano de 2019, os dados foram extraidos de planinhas disponíveis no site do Instituto Brasileiro de Geografia e Estatística (IBGE) para isso utiliza-se  como variáveis explicativas (covariáveis):

**Pobreza**: Que fornece a taxa de extrema pobreza no ano 2019;

**Densidade Demográfica**: Informa a densidade demográfica de cada estado no ano de 2019;  

**Área** : Refere-se a área em km de cada estado no ano de 2019; 

**Índice de Desenvolvimento Humano  Educacional** (IDHe) : Refere-se ao IDH educacional no de ano de 2017, a escolha das covariáveis foram para conter três eixos:

*População e Geográfia do Estado*: Área e Densidade Demográfica;

*Condição de Vida*: Pobreza;

*Educação* : IDHe.


\section{Análise Descritiva}
Nesta seção veremos um breve resumo das variáveis de estudo, com medidas descritivas, medidas de dispresão e gráficos de dispersão.

Começaremos por uma tabela resumo, com informações sobre as covariáveis:
```{r}
df %>% 
  select(-UF,-Região) %>% 
  psych::describe() %>% 
  .[,-c(1,6,7,10,11,13,12)] %>% 
  rename(Média=mean,`Desvio Padrão`=sd,Mediana=median,Minímo=min,Máximo=max) %>% 
  round(3) %>%
  tbl("Resumo das variáveis: ")
```
Note pelo seguinte gráfico que os estados da região Norte estão bem próximos da média do PIB per capita por estado (`r mean(df$PIB)`), SP  e RJ estão bem acima e os estados da região nordeste estão bem abaixo.
```{r graphstates}
df %>% 
  ggplot(aes(PIB,fct_reorder(UF,PIB),fill=Região)) +
  geom_bar(stat="identity")+
  geom_text(aes(label=PIB), hjust=-0.007,size=3.6)+
  labs(title="PIB por estado",y="Estado") + scale_x_continuous(
    expand = c(0.01, 0),limits = c(0, 53000))
```
A título de curiosidade vejamos o PIB por região

```{r }
df %>% 
  group_by(Região) %>% 
  summarise(`Média PIB`=mean(PIB),`Desvio padrão`=sqrt(var(PIB)), Estados=n()) %>% 
  tbl("PIB por Região")
```
Note que, em média a região Sul possui maior PIB médio e com menor variância, a região Sudeste possui a maior variação no PIB dado o fato que possui duas regiões com PIBs discrepantes em relação aos demais.  

Para o eixo condição de vida, perceba a relação entre **Pobreza** e o **PIB** pelo seguinte gráfico de dispersão:
```{r}
df %>% 
  d(Pobreza,PIB,0.20)+
  labs(title="Gráfico de dispersão entre Pobreza e PIB")
```
É possivel ver pelo gráfico e pela correlação de `r round(cor(df$PIB,df$Pobreza),3)` que quanto maior for a taxa de pobreza do estado, menor será seu PIB.


Para o eixo Educação, perceba a relação entre **IDHe** e  o **PIB** pelo seguinte gráfico de dispersão:

```{r}
df %>% 
  d(IDHe,PIB,0.67)+
  labs(title="Gráfico de dispersão entre IDHe e PIB")
```
Pode-se ver pelo gráfico e pela correlação de `r round(cor(df$PIB,df$IDHe),3)` que quanto maior for a IDHe, maior será seu PIB.

E para o eixo População e Geográfia do Estado tem-se o gráfico de dispersão:

```{r}
df %>% 
  d(`Densidade Demográfica`,PIB,200)+
  labs(title="Gráfico de dispersão entre Densidade Demográfica e PIB")
```
Duas observações se destacam das outras, pois possuem uma densidade demográfica bastante superior a média, sendo elas São Paulo e Rio de Janeiro, pelo gráfico de dispersão não fica muito claro o comportamento da relação entre PIB e Densidade Demográfica, a correlação de `r round(cor(df$PIB,df$"Densidade Demográfica"),3)` indica que é uma correlação positiva entretanto fraca.
```{r}
df %>% 
  select(-UF,-Região) %>% 
   cor() %>% 
  round(3) %>%
 tbl("Correlação entre as variáveis")
```

Podemos notar nos valores observados das variáveis que existe um pouco de correlação nas covariáveis, testaremos mais a frente a existência de multicolineriadade. 




```{r mod21}
fit1=
  linear_reg() %>% 
  set_engine("lm") %>% 
  fit(PIB~.,data=df1 %>% 
        select(-UF,-Região))
fit2=
  linear_reg() %>% 
  set_engine("lm") %>% 
  fit(PIB~.,data=df %>% 
        select(-UF,-Região))
  
ft1=fit1$fit
ft2=fit2$fit
residuo = rstudent(ft2)
residuo1 = rstudent(ft1)
n = dim(df)[1]
n1 = dim(df1)[1]
```


\section{Análise de Influência}
É possível notar que toda a análise descritiva foi realizada utilizando apenas os 26 estados brasileiros, sem o Distrito Federal, pois em uma Análise de Influência prévia foi analisado que esse estado é um ponto influente no nosso modelo, como será demonstrado nesta seção e no modelo de regressão linear. 

Então é necessário ver se existem observações atípicas no conjunto dados, que podem estar influenciando a análise.

No gráfico a seguir vemos as medidas de alavancagem, que  informam se uma observação é discrepante em termos de covariável, nota-se que apenas uma observação está um pouco fora dos limites pré-estabelecidos:

```{r alavancagem}
h_bar=ft2$rank/ n
hatvalues(ft2) %>% 
  graph(3*h_bar)+
  labs(title="Alavancagem no banco ajustado",y="Medida de Alavancagem") +
    ggrepel::geom_text_repel(aes(label=df$UF),size=2.8,point.padding = 0.3)
```
A Alanvancagem no banco original, fica com apenas o DF acima dos limites, mas bem próximo:

```{r alavancagem2}
h_bar=ft1$rank/n1
hatvalues(ft1) %>% 
  graph(3*h_bar)+
  labs(title="Alavancagem no banco original",y="Medida de Alavancagem") +
    ggrepel::geom_text_repel(aes(label=df1$UF),size=2.8,point.padding = 0.3)
```

No diagnóstico dffits, que informam o grau de influência que a observação $i$ tem sobre o valor seu próprio valor ajustado $\hat{y_i}$, percebe-se somente uma observação levemente fora dos limites:

```{r dffits}
dffits(ft2) %>% 
 graph(2*sqrt(ft2$rank / n))+
  labs(title="Dffits do banco ajustado",y="Dffits") +
    ggrepel::geom_text_repel(aes(label=df$UF),size=2.8,point.padding = 0.3)
```
No Dffits do banco original, podemos perceber que o DF é um candidato a ponto de influencia, por estar muito acima do limite, achatando o gráfico e o RJ um pouco abaixo do limite:

```{r dffits2}
dffits(ft1) %>% 
 graph(2*sqrt(ft1$rank/n1))+
  labs(title="Dffits do banco original",y="Dffits") +
    ggrepel::geom_text_repel(aes(label=df1$UF),size=2.8,point.padding = 0.3)
```

Tem-se também a distância de cook, que fornece a influência da observação $i$ sobre todos os $n$ valores ajustados, novamente com apenas o RJ acima dos limites estipulados:

```{r cook}
cooks.distance(ft2) %>% 
  graph(4/(n-ft2$rank ))+
  labs(title="Distância de Cook do banco ajustado",y="Dis Cook") +
    ggrepel::geom_text_repel(aes(label=df$UF),size=2.8,point.padding = 0.3)
```
Na Distância de Cook do banco inicial podemos ver que o DF reincidente como um ponto extremamente fora dos limites achatando o gráfico, e o RJ também está acima:

```{r cook1}
cooks.distance(ft1) %>% 
  graph(4/(n1-ft1$rank ))+
  labs(title="Distância de Cook do banco original",y="Dis cook") +
    ggrepel::geom_text_repel(aes(label=df1$UF),size=2.8,point.padding = 0.3)
```
O gráfico de resíduos também é importante para verificarmos visualmente a média dos resíduos e se existe algum valor fora do limite de 3 desvios padrões, pois esses possui baixíssima probabilidade de serem observados, no gráfico abaixo verificamos que todos os estados estão dentro dos limites: 

```{r residuos}
# residuo
 # residuo studentizado
residuo %>% 
  graph(3)+
  geom_hline(yintercept = 0, linetype="dotted", color = "deepskyblue2")+
  labs(title="Residuos do Banco Ajustado",y="Resíduo")+
    ggrepel::geom_text_repel(aes(label=df$UF),size=2.8,point.padding = 0.3)
```

Abaixo percebemos que também no gráfico de resíduos studentizados, o DF é um candidato a ponto influente do modelo, assim como o RJ, porém no modelo ajustado, o RJ não fica fora do limite, tornando assim mais uma evidência da influência do DF no modelo:

```{r residuos1}
residuo1 %>% 
  graph(3)+
  geom_hline(yintercept = 0, linetype="dotted", color = "deepskyblue2")+
  labs(title="Residuos do Banco Original",y="Resíduo")+
    ggrepel::geom_text_repel(aes(label=df1$UF),size=2.8,point.padding = 0.3)
```
E por último tem-se o gráfico de envelope simulado, que informa se a distribuição proposta para os dados está em conforme com os valores observados, percebe-se todos os valores dentros das bandas simuladas:

```{r env,comment=NA}
residuo %>% 
  as_tibble() %>% 
  ggplot(aes(sample = value)) +
  qqplotr::geom_qq_band(alpha = 0.5, fill="white", col="black",B=150,bandType = "boot") +
  qqplotr::stat_qq_line(size=0.5, linetype="dashed") + 
  qqplotr::stat_qq_point(size=1.3) +
  scale_fill_discrete("Bandtype")+
  labs(x = "Quantis teóricos", y = "Quantis amostrais",title="Envelope Simulado banco ajustado")
```

Ao extremo contrário do envelope simulado do banco original, em que podemos perceber pontos fora das bandas simuladas: 

```{r env2,comment=NA}
residuo1 %>% 
  as_tibble() %>% 
  ggplot(aes(sample = value)) +
  qqplotr::geom_qq_band(alpha = 0.5, fill="white", col="black",B=150,bandType = "pointwise") +
  qqplotr::stat_qq_line(size=0.5, linetype="dashed") + 
  qqplotr::stat_qq_point(size=1.3) +
  scale_fill_discrete("Bandtype")+
  labs(x = "Quantis teóricos", y = "Quantis amostrais",title="Envelope Simulado banco original")
```
**Por que o Distrito Federal é um ponto influente?**


Porque é a capital do país, sendo assim a única das 27 unidades federativas que não é um estado, foi estritamente planejada por Juscelino Kubitschek para ser o polo político e diplomátido do país, assim também sendo uma maneira de desenvolver outras regiões do país, no caso a Região Centro-Oeste. Ao contrário  de todos os outros estados, que em sua grande maioria não tiveram nenhum planejamento estatal. 

Notamos que por ser a unidade federativa com a menor área, porém com grande relevância política, com o maior IDH e a maior densidade demográfica, sendo essas covariáveis do nosso modelo, pois em sua maioria é composto por pessoas ligadas a instituições públicas, assim sendo perceptível a sua diferença perante as outras unidades federativas.

\section{Verificação dos pressupostos}

Precisamos primeiramente testar se os modelos estão corretamente especificados, faremos pelo teste Reset que tem como hipótese nula que o modelo está corretamente especificado, fazendo o teste para o modelo de regressão ajustado obtem-se um  p-valor igual a `r lmtest::resettest(ft2)$p.value` que nos informa que não existem indicativos contra a hipótese suposta.

No entanto considerando o banco de dados original obtem-se um p-valor << 0.001, então rejeitamos a hipótese nula e concluímos que  há indicativos para não utilizarmos o modelo do banco de dados original, contendo o Distrito Federal. Assim lidaremos com  o modelo ajustado.


Agora iremos verificar os seguintes pressupostos, para utilização correta do modelo de regressão linear: 

Precisamos testar se os erros ($\epsilon_i$) possuem média zero, variância constante, não-autocorrelação, e seguem uma distribuição normal ($N$) . Podemos encapsular todos esses pressupostos dizendo que $\epsilon_i \sim N(0,\sigma^2)$, ainda é necessário também testar não dependência linear entre as covariáveis.

Primeiramente vamos testar se os erros  possuem média zero, para isso usaremos um teste t que tem  como  hipótese:
 $$H_0: E(\epsilon_i)= 0$$ 
Obtem-se um p-valor >> $0.1$, portanto manteremos a hipótese de média nula dos erros.

Segundo precisamos testar  a hipótese de variância constante dos erros, usaremos o Teste de Bressch-Pagan, que tem por hipótese:
$$H_0: Var(\epsilon_i)= \sigma^2$$


Obtém-se um p-valor de `r lmtest::bptest(ft2, studentize = TRUE)$p.value` que também informa que não possuímos evidências amostrais contra a hipótese proposta.

Agora fazemos o teste de normalidade, utilizando o teste de Jarque-Bera, obtivemos um p-valor de `r tseries::jarque.bera.test(residuo)$p.value`, assim não rejeitando a hipótese nula, que é a existência normalidade dos erros.

Como podemos analisar no histograma dos resíduos abaixos, que se assemelha a distribuição normal:

```{r}
residuo %>% 
  tibble(res=.) %>% 
  ggplot(aes(res))+
 geom_histogram(breaks=seq(-2.418-0.8,2.117+0.8,1),
                 fill="white", colour="black")+
  labs(x="Resíduo",title="Histograma dos resíduos")
```

Como informado no início também é necessário testar se existe multicolinearidade, para tal usa-se fatores de inflação da variância (vif) para detectar, é ideal é que vif=1 e o máximo para não multicolinearidade é 5, obtemos `r car::vif(ft2)` para as variáveis $x_1$, $x_2$, $x_3$ e $x_4$ respectivamente.

E por último é necessário testar a existência de autocorrelação, usaremos o Teste de Durbin-Watson, que tem por hipótese, a não existência de correlação, após aplicação do teste obtém-se um p-valor de `r lmtest::dwtest(ft2)$p.value` i.e, não existem indicío contra a hipótese de autocorrelação.

Logo, pelo testes anteriores não existem evidências contra os pressupostos teóricos, com isso podemos estabelecer inferência para os parâmetros do modelo.
```{r média zero,include=FALSE}
## Teste t para a média dos errros
## H0: média dos erros eh igual a zero
t.test(resid(ft2),mu=0,alternative="two.sided") 
```

```{r var const,include=F}
## Teste de Bressch-Pagan (Koenker) de Heteroscedasticidade
## H0: erros sao homoscedasticos
lmtest::bptest(ft2, studentize = TRUE)
```

```{r autocor,include=F}
## Teste de Durbin-Watson de autocorrelacao
## H0: : Nao autocorrelacao 
lmtest::dwtest(ft2) 
```

```{r multi,include=F}
## Regra de bolso: vif > 5 indica multicolinearidade. vif=1 seria o ideal.
car::vif(ft2)  
```

```{r normalidade,include=F}
## Teste Jarque-Bera de Normalidade
## H0: Os erros possuem distribuicao normal
tseries::jarque.bera.test(residuo)
```

\section{Ajuste Final}

Tem-se  portanto como resumo do modelo final a seguinte tabela:
```{r}
tidy(fit2) %>% 
  select(-statistic) %>% 
  kable(caption="Resumo do modelo final",align = "c",col.names = c("Coeficientes","Estimativa","Erro Padrão","p-valor"),digits = 3) %>% 
  footnote(general = "Na verdade, o p-valor com maior precisão  do teste de significância associado a  Pobreza é: 0,0000048 ",footnote_as_chunk = T, title_format = c("italic", "underline")) %>% 
  kable_classic(latex_options = "HOLD_position") 
  
```
Que informa que o intercepto não é significativo a 5%. Tem-se um p-valor << 0.001 do teste F e $R^2$ dado por `r round(glance(ft2)[1],3)` que informa que aproximadamente `r round(glance(ft2)[1],3)*100`% da variação do PIB per capita dos estados é explicada pelas covariáveis propostas.

Assim um estado com IDHe máximo (1) adicionaria 70.391,625 reais ao PIB per capita, sendo o maior IDHe existente 0,828 e o maior PIB per capita 47008,77, da mesma maneira que um estado com a Incidência de Pobreza máxima (1), sendo o maior existente 0,263, reduziria 80336,96 reais na variável. A influência da área é de apenas 0,004, ou seja, a cada 1 $km^2$ adiciona 0,004 reais ao PIB per capita, assim como a influência da densidade demográfica é que a cada 1 $hab/km^2$ adiciona 22,830 reais.

\section{Apêndice}
Temos conteúdo extra ao trabalho principal que serão indexados nessa seção, que estão relacionados ao objetivo, mas não correspondem ao fundamental do projeto, porém são pertinentes para os leitores mais interessados.




\subsection{Apêndice A: Análise de Influência e Descritiva Extra}

Neste apêndice serão feitas análises extras que são interessante para a compreensão da variável desfecho, mas não necessariamente fundamentais, que pode ser acessado clicando [\textcolor{red}{aqui}](https://github.com/AlissonRP/gdp-statesBR/blob/main/extra.pdf).

\subsection{Apêndice B: Código Completo}
O código completo pode ser acessado  [\textcolor{red}{aqui}](https://github.com/AlissonRP/gdp-statesBR/blob/main/relatorio.Rmd).