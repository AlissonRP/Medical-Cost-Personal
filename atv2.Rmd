---
title: "Trabalho 2 Análise de Regressão"
author: "Alisson Rosa e Vítor Perira"
header-includes:
   - \usepackage[brazil]{babel}
geometry: margin=2cm
output:
  bookdown::pdf_document2:
editor_options:
  chunk_output_type: console
---



```{r setup,include=F}
 
library('tidyverse')
library("tidymodels")
library('kableExtra')
options(digits=3)
theme_set(theme_bw())
knitr::opts_chunk$set(echo=FALSE,message=F,warning=F,fig.pos = 'H',fig.align = 'center',fig.width=7.8, fig.height=3.3)
scale_fill_discrete = \(...) scale_fill_brewer(... , palette="Set2")
df=read_csv("https://raw.githubusercontent.com/AlissonRP/gdp-statesBR/main/df")

df=df %>% 
  select(UF,PIB=GDP,IDHe=`HDI Education 2017`,Área=Area,`Densidade Demográfica`=`Demographic Density`,Pobreza=Poverty) %>% 
  .[-7,]


```


```{r, funções}




#Dispersão/ correlação
d=function(df,v1,v2,px){
  df %>% 
    ggplot(aes({{v1}},{{v2}})) +
    geom_point(size=2.1,color="red")+
    annotate(x=px, y=55000, 
         label=paste("Correlação= ", round(cor(df %>% 
                                         select({{v1}}),df %>% 
                                         select({{v2}})),2)), 
         geom="text", size=5)+
    ggrepel::geom_text_repel(aes(label=UF),size=2.8,point.padding = 0.3)
}

tbl=function(v,tit){
  v %>% 
    kable(caption=tit,align = "c") |> 
  kable_classic(latex_options = "HOLD_position") 
}

graph=function(df,l){
  df %>% 
    as_tibble() %>% 
      ggplot(aes(as.numeric(row.names(df  %>% as_tibble())),value))+
      geom_point(shape=1)+
      geom_hline(yintercept=l, linetype="dashed", color = "red")+
      geom_hline(yintercept=-l, linetype="dashed", color = "red")+
      labs(x="Índice")
    
}
```

\section{Introdução}
A proposta do respectivo trabalho é predizer o produto interno bruto (PIB) de 26 estados do Brasil no ano de 2019, os dados foram extraidos de planinhas disponíveis no site do Instituto Brasileiro de Geografia e Estatística (IBGE) para isso utiliza-se  como variáveis explicativas (covariáveis):
**Pobreza**: Que fornece a taxa de extrema pobreza no ano 2010;  
**Densidade Demográfica**: Informa a densidade demográfica de cada estado no ano de 2019;  
**Área** : Refere-se a área em km de cada estado no ano de 2019; 
**índice de Desenvolvimento Humano (IDHe) Educacional**: Refere-se ao IDH educacional no de ano de 2017, a escolha das covariáveis foram para conter três eixos:

**População e Geográfia do Estado**: Área e Densidade Demográfica
**Condição de Vida**: Pobreza
e **Educação** : IDHe
Como modelos de preditivos foi utilizado  uma regressão linear, florestas aleatórias (rf)  e os k-vizinhos mais próximos (knn)

\section{Análise Descritiva}
Vejamos um breve resumo das variáveis de estudo :
```{r}
df %>% 
  select(-UF) %>% 
  psych::describe() %>% 
  .[,-c(1,6,7,10,11,13,12)] %>% 
  rename(Média=mean,`Desvio Padrão`=sd,Mediana=median,Minímo=min,Máximo=max) %>% 
  tbl("Resumo das variáveis: ")
  

```
Para o eixo condição de vida, perceba a relação entre **Pobreza** e e o **PIB** pelo seguinte gráfico de dispersão:
```{r}
df %>% 
  d(Pobreza,PIB,0.20)+
  labs(title="Gráfico de dispersão entre Pobreza e PIB")


```
Pode-se ver pelo gráfico e pela correlação de `r round(cor(df$PIB,df$Pobreza),3)` que quanto maior for a taxa de pobreza do estado, menor será seu PIB.


Para o eixo Educação, perceba a relação entre **IDHe** e  o **PIB** pelo seguinte gráfico de dispersão:

```{r}
df %>% 
  d(IDHe,PIB,0.67)+
  labs(title="Gráfico de dispersão entre IDHe e PIB")
  
```
Pode-se ver pelo gráfico e pela correlação de `r round(cor(df$PIB,df$IDHe),3)` que quanto maior for a IDHe, maior será seu PIB.

E para o eixo População e Geográfia do Estado tem-se o gráfico de dispersão:

```{r}
df %>% 
  d(`Densidade Demográfica`,PIB,200)+
  labs(title="Gráfico de dispersão entre IDHe e PIB")
```
Duas observações se destacam das outras, pois possuem uma densidade demográfica bastante superior a média, sendo elas São Paulo e Rio de Janeiro, pelo gráfico de dispersão não fica muito claro o comportamento da relação entre PIB e Densidade Demográfica, a correlação de `r `round(cor(df$PIB,df$`Densidade Demográfica`),3)` indica que é uma correlação positiva entretanto fraca.
```{r}
df %>% 
  select(-UF) %>% 
   cor() %>% 
 tbl("Correlação entre as variáveis")
```

Podemos notar nos valores observados das variáveis que existe um pouco de correlação nas covariáveis, testaremos mais a frente a existência de multicolineriadade. 




\section{Ajuste dos Modelos}
Nessa seção serão ajustados os modelos de regressão linear, rf e knn [^1], usando as covariáveis já citadas.  
Os hiperparâmetros dos modelos que possuem, foram encontrados por otimização, tentando minimizar a raiz do erro quadrático médio (rmse). O seguinte gráfico ilustra o rmse para cada modelo 




```{r mod1}
set.seed(4)
df_boot=
  df %>% 
  select(-UF) %>% 
  bootstraps(15)

df_rec1=df %>%
  select(-UF) %>% 
  recipe(PIB~.)




```


```{r mod2}
df_reg=
  linear_reg() %>% 
  set_engine("lm")

df_rf=
  rand_forest(trees=500,mtry=3,min_n =7) %>% 
  set_mode("regression") %>% 
  set_engine("ranger",importance = "impurity")

df_knn= nearest_neighbor(mode="regression",neighbors =8) %>% 
  set_engine("kknn")

```
```{r}
df_work=
   workflow_set(list(df_rec1),list(reg=df_reg,rf=df_rf,knn=df_knn),cross = T)
```

```{r}
set.seed(4)
doParallel::registerDoParallel(cores=2)
df_tuner=df_work %>% 
  workflow_map("tune_grid",
               resamples=df_boot,         
               grid=15,
               metrics=metric_set(rmse),verbose = T) 
autoplot(df_tuner)+
  labs(title="Comparação dos modelos ajustados",x="Rank do modelo",y="Métrica")
rank_results(df_tuner,rank_metric = "rmse") %>% view()

fit1=df_tuner %>% 
  extract_workflow(id="recipe_rf") %>% 
  fit(df)                 
                                  
fit2=df_tuner %>% 
  extract_workflow(id="recipe_reg") %>%
  fit(df)



ft1=fit1$fit$fit$fit
ft2=fit2$fit$fit$fit
residuo = rstudent(ft2)

```



\section{Verificação dos pressupostos}

Precisamos primeiramente testar se os modelos estão corretamente especificados, faremos pelo teste Reset que tem como hipótese nula que o modelo está corretamente especificado, fazendo o teste para o $modelo_1$ obtém-se um p-valor < 0.001 o que indica evidências de que nosso modelo não está  bem ajustado, o teste para o $modelo_2$ possui p-valor igual a `r lmtest::resettest(ft2)$p.value` que nos informa que não existem evidências contra a hipótese suposta, portanto, a partir de agora o $modelo_1$ será abandonado e toda análise seguinte será sobre o $modelo_2$, portanto a partir de agora modelo refere-se ao com $x_1$ ao quadrado.

É necessário ver se existem observações atípicas no conjunto dados, que podem estar influenciando a análise:

```{r}
n=length(df$Área)
```
\subsection{Análise de Influência}
No gráfico a seguir vemos as medidas de alavancagem, que  informam se uma observação é discrepante em termos de covariável, nota-se que apenas uma observação está um pouco fora dos limites pré-estabelecidos
```{r alavancagem}

h_bar=ft2$rank / n

hatvalues(ft2) %>% 
  graph(3*h_bar)+
  labs(title="Alavancagem",y="Medida de Alavancagem")

```
Temos  dffits, que informam o grau de influência que a observação $i$ tem sobre o valor seu próprio valor ajustado $\hat{y_i}$, percebe-se somente uma observação levemente fora dos limites
```{r dffits}

dffits(ft2) %>% 
 graph(2*sqrt(ft2$rank / n))+
  labs(title="dffit")+
  labs(title="dffit vs índice",y="dffit")


  


```
Tem-se também a distância de cook, que fornece a influência da observação $i$ sobre todos os $n$ valores ajustados
```{r cook}


cooks.distance(ft2) %>% 
  graph(4/(n-ft2$rank ))+
  labs(title="Distância de cook vs indíces",y="Dis cook")
#


```
O gráfico de resíduos também é importante para verificarmos visualmente a média dos res´sduos e se existe algum valor fora de 3 desvios padrões, pois esse possui baixíssima probabilidade de serem observados.
```{r residuos}
# residuo
 # residuo studentizado
residuo %>% 
  graph(3)+
  geom_hline(yintercept = 0, linetype="dashed", color = "blue")+
  labs(title="residuo vs índice",y="Resíduo")




residuo %>% 
  tibble(res=.) %>% 
  ggplot(aes(res))+
 geom_histogram(breaks=seq(-1.993,2.289 +0.01,0.5),
                 fill="white", colour="black")+
  labs(x="Resíduo",title="Histograma dos resíduos")


```
E por último tem-se o gráfico de envelope simulado, que informa se a distribuição proposta para os dados está em conforme com os valores observados, percebe-se todos os valores dentros das bandas simuladas
```{r env,comment=NA}
residuo %>% 
  as_tibble() %>% 
  ggplot(aes(sample = value)) +
  qqplotr::geom_qq_band(alpha = 0.5, fill="white", col="black",B=150,bandType = "boot") +
  qqplotr::stat_qq_line(size=0.5, linetype="dashed") + 
  qqplotr::stat_qq_point(size=1.3) +
  scale_fill_discrete("Bandtype")+
  labs(x = "Quantis teóricos", y = "Quantis amostrais",title="Envelope Simulado")


```

```{r}
#Ajustado vs observadp
ft2$fitted.values %>% 
  bind_cols(fit=.,y=df$PIB) %>% 
  ggplot(aes(fit,y)) + 
  geom_point()+
  geom_abline(intercept = 0,slope=1)
```


\subsection{Teste de hipótese dos pressupostos}

Primeiramente vamos testar se os erros ($\epsilon$) possuem média zero, para isso usaremos um teste t que tem  como  hipótese:
 $$H_0: E(\epsilon_i)= 0$$ 
Obtem-se um p-valor >> $0.1$, portanto manteremos a hipótese de média nula dos erros.

Segundo precisamos testar  a hipótese de variância constante dos erros, usaremos o Teste de Bressch-Pagan, que tem por hipótese:
$$H_0: Var(\epsilon_i)= \sigma^2$$




Obtém-se um p-valor de `r lmtest::bptest(ft2, studentize = TRUE)$p.value` que também informa que não possuímos evidências amostrais contra a hipótese proposta.

Agora fazemos o teste de normalidade, utilizando o teste de Jarque-Bera, obtivemos um p-valor de `r tseries::jarque.bera.test(residuo)$p.value` que também informa que não existem evidência contra normalidade dos erros

Como informado no início também é necessário testar se existe multicolinearidade, para tal usa-se fatores de inflação da variância (vif) para detectar, é ideal é que vif=1, obtemos `r car::vif(ft2)` para as variáveis $x_1$,$x_2$,$x_3$ e $x_4$ respectivamente.

E por último é necessário testar a existência de autocorrelação, usaremos o Teste de Durbin-Watson, que tem por hipótese, que existe não existe correlação, após aplicação do teste obtém-se um p-valor de `r lmtest::dwtest(ft2)$p.value` i.e, não existem evidências contra a hipótese de autocorrelação.

Logo, pelo testes anteriores não existem evidências contra os pressupostos teóricos, com isso podemos estabelecer inferência para os parâmetros do modelo
```{r média zero,include=FALSE}

## Teste t para a média dos errros
## H0: média dos erros eh igual a zero
t.test(resid(ft2),mu=0,alternative="two.sided") 

```

```{r var const,include=F}

## Teste de Bressch-Pagan (Koenker) de Heteroscedasticidade
## H0: erros sao homoscedasticos
lmtest::bptest(ft2, studentize = TRUE)
```



```{r autocor,include=F}

## Teste de Durbin-Watson de autocorrelacao
## H0: : Nao autocorrelacao 
lmtest::dwtest(ft2) 
```

```{r multi,include=F}


## Regra de bolso: vif > 10 indica multicolinearidade. vif=1 seria o ideal.
car::vif(ft2)  
```

```{r normalidade,include=F}

## Teste Jarque-Bera de Normalidade
## H0: Os erros possuem distribuicao normal
tseries::jarque.bera.test(residuo)

```
\section{Ajuste final}

Tem-se  portanto como resumo do modelo final a seguinte tabela:
```{r}

   
tidy(fit2) %>% 
  select(-statistic) %>% 
  kable(caption="Resumo do modelo final",align = "c",col.names = c("Coeficientes","Estimativa","Erro Padrão","p-valor"),digits = 4) %>% 
  kable_classic(latex_options = "HOLD_position") 
```
Que informa que o intercepto e o coeficiente de $x_2$ não são significativos a 1%, tem-se um p-valor << 0.001 do teste F e $R^2$ dado por `r round(glance(ft2)[1],3)` que informa que aproximadamente `r round(glance(ft2)[1],3)*100`% da variação do PIB dos estados é explicada pelas covariáveis propostas.

\section{Comentário} 
O código completo pode ser acessado  [aqui](https://github.com/AlissonRP/RegressaoATV_2).

[^1]: Evidentemente, a escolha de colocar mais modelos foi só por motivos de comparação de desempenho, não foi aprofundado i.e, realizado seperação entre treino e  teste etc



